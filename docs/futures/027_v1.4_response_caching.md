# Agent Result Caching

> **Versão Target:** V1.4
> **Status:** ⏳ Pendente
> **Owner:** Unassigned
> **Estimativa:** 20h

---

## Descrição

Perguntas similares triggam pipeline completo toda vez. Desperdício de recursos e custo OpenAI.

---

## Passos de Implementação

### 1. Código

- [ ] `src/utils/response_cache.py`: Cache layer com Redis
  - Semantic similarity check (not just exact match)
  - TTL configurável
  - Company-scoped cache
- [ ] `src/utils/pipeline.py`: Check cache before running agents
- [ ] `src/api/admin_routes.py`: Cache invalidation endpoint

### 2. Testes

- [ ] Unit tests: Cache hit/miss logic
- [ ] Integration tests: Cached response accuracy
- [ ] Performance tests: Latency improvement

### 3. Documentação

- [ ] `docs/CACHING.md`: Cache strategy

### 4. Infraestrutura

- [ ] Redis setup
- [ ] Cache monitoring (hit rate)
- [ ] Invalidation on KB update

---

## Dependências

- Redis infraestrutura

---

## Notas de Expansão

- Semantic caching (similar questions, not just exact matches)
- Per-company cache isolation
- Cache warm-up from historical data
- Cache analytics dashboard

---

## Referências

- [FEATURE_RESEARCH.md](../FEATURE_RESEARCH.md)
