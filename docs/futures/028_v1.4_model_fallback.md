# Model Fallback Hierarchy

> **Versão Target:** V1.4
> **Status:** ⏳ Pendente
> **Owner:** Unassigned
> **Estimativa:** 25h

---

## Descrição

Se OpenAI falha ou quota excedida, pipeline para. Precisa de fallbacks para high availability.

---

## Passos de Implementação

### 1. Código

- [ ] `src/utils/llm_client.py`: Multi-provider client
  - Primary: OpenAI GPT-4
  - Fallback 1: OpenAI GPT-3.5 (cheaper)
  - Fallback 2: Anthropic Claude
  - Fallback 3: Rule-based logic
- [ ] `src/config.py`: Fallback configuration
- [ ] `src/utils/circuit_breaker.py`: Integrar com fallback logic
- [ ] Metrics: Track which model is being used

### 2. Testes

- [ ] Unit tests: Fallback triggering
- [ ] Integration tests: E2E com primary failure

### 3. Documentação

- [ ] Atualizar docs/CIRCUIT_BREAKER.md

### 4. Infraestrutura

- [ ] Anthropic API key
- [ ] Cost tracking per model

---

## Dependências

- Circuit Breaker já implementado

---

## Notas de Expansão

- Smart routing (use GPT-4 for complex, GPT-3.5 for simple)
- Cost optimization mode (always try cheap model first)
- Multi-model voting for critical decisions
- Latency-based routing

---

## Referências

- [FEATURE_RESEARCH.md](../FEATURE_RESEARCH.md)
